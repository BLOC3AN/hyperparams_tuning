{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ec5f86-44e4-4d12-8292-c3f6abc97d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import polars as pl\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b284a171-a697-48e6-9eb5-853df3709c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bilstm(trial):\n",
    "    model_BiLSTM = Sequential([\n",
    "            Input(shape=(100, features)),\n",
    "\n",
    "\n",
    "            Bidirectional(LSTM(\n",
    "                units = trial.suggest_int(\"units_1\", 64, 256, step=32),\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=regularizers.l1_l2(\n",
    "                    l1=trial.suggest_float(\"l1_1_layer1\", 1e-3, 3e-1),\n",
    "                    l2=trial.suggest_float(\"l2_1_layer1\", 1e-3, 3e-1),\n",
    "                    ),\n",
    "                recurrent_regularizer=regularizers.l1_l2(\n",
    "                    l1=trial.suggest_float(\"l1_2_layer1\", 1e-3, 3e-1),\n",
    "                    l2=trial.suggest_float(\"l2_2_layer1\", 1e-3, 3e-1),\n",
    "                    ),\n",
    "                )),\n",
    "            Dropout(trial.suggest_float(\"dropout_1\", 1e-5,1e-2)),\n",
    "            Bidirectional(LSTM(\n",
    "                units = trial.suggest_int(\"units_2\", 64, 256, step = 32),\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=regularizers.l2(\n",
    "                    l2 = trial.suggest_float(\"l2_1_layer2\", 1e-3, 3e-1)\n",
    "                    ),\n",
    "                recurrent_regularizer=regularizers.l2(\n",
    "                    l2 = trial.suggest_float(\"l2_2_layer2\", 1e-3, 3e-1)\n",
    "                    ),\n",
    "                )),\n",
    "\n",
    "            Dropout(trial.suggest_float(\"dropout_2\", 1e-3, 3e-1)),\n",
    "            Bidirectional(LSTM(\n",
    "                units = trial.suggest_int(\"units_3\", 64, 256, step = 32),\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=regularizers.l2(\n",
    "                    l2 = trial.suggest_float(\"l2_1_layer3\", 1e-3, 3e-1)\n",
    "                    ),\n",
    "                recurrent_regularizer=regularizers.l2(\n",
    "                    l2 = trial.suggest_float(\"l2_2_layer3\", 1e-3, 3e-1)\n",
    "                    ),\n",
    "                )) ,\n",
    "\n",
    "            Dropout(trial.suggest_float(\"dropout_3\", 1e-3, 3e-1)),\n",
    "            Bidirectional(LSTM(\n",
    "                units= trial.suggest_int(\"unit_4\", 32,256, step = 32) ,\n",
    "                return_sequences=True)),\n",
    "            Dropout(trial.suggest_float(\"dropout_4\", 1e-3, 3e-1)),\n",
    "            Bidirectional(LSTM(\n",
    "                units= trial.suggest_int(\"unit_5\", 32,256, step = 32) ,\n",
    "                return_sequences=True)),\n",
    "\n",
    "            Dense(units = trial.suggest_int(\"Dense_1\", 64,256, step = 32), activation = 'relu'),\n",
    "            Dense(units = trial.suggest_int(\"Dense_2\", 64,256, step = 32), activation = 'relu'),\n",
    "            Dense(targets)\n",
    "        ])\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-3, 3e-1)\n",
    "    model_BiLSTM.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipnorm=trial.suggest_float(\"clip_norm\", 1.0, 3.0)),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.MeanSquaredError(name='mse'),\n",
    "                 tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "                ]\n",
    "    )\n",
    "    return model_BiLSTM\n",
    "\n",
    "def objective(trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    model = build_bilstm(trial)\n",
    "    history = model.fit(\n",
    "        X_train_split_reshape, y_train_split_reshape,\n",
    "        validation_data=validation_data,\n",
    "        epochs=100, \n",
    "        batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=10, min_lr=1e-5)\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    tf.keras.backend.clear_session()\n",
    "    return min(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cae8c4c-0b0c-47ca-be95-61622add8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"/workspace/data.csv\")\n",
    "columns = [\n",
    "'noperation','nsampling','valve','voltage','current','pressure','torque',\n",
    " 'theta0','theta1','theta2',\n",
    " 'cos1','cos2_inv','cos2_inv2','cos2_inv3',\n",
    " 'd_valve','d_press','dv_sign','status']\n",
    "\n",
    "X = df[columns].drop('torque')\n",
    "y = df[['torque']]\n",
    "\n",
    "\n",
    "features = len(X.columns)\n",
    "targets = len(y.columns)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X)\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_scaler,y, test_size= 0.25)\n",
    "\n",
    "X_train_split_reshape = X_train_split.reshape(X_train_split.shape[0]//100, 100, features)\n",
    "\n",
    "X_val_reshape = X_val.reshape(X_val.shape[0]//100, 100, features)\n",
    "\n",
    "y_train_split_reshape = y_train_split.to_numpy().reshape(y_train_split.shape[0]//100,100,targets)\n",
    "y_val_reshape = y_val.to_numpy().reshape(y_val.shape[0]//100,100,targets)\n",
    "\n",
    "validation_data = (X_val_reshape, y_val_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e499a1-82b9-4387-adc6-627317202405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 03:40:25,544] A new study created in memory with name: no-name-ea31f337-effb-4a86-8e32-4ccfc3b6869a\n",
      "2025-02-21 03:40:26.041174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14301 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2025-02-21 03:40:26.576948: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "/tmp/ipykernel_1165/1600206865.py:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-3, 3e-1)\n",
      "2025-02-21 03:40:40.698409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8905\n",
      "2025-02-21 03:40:43.089700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x74bdfd816380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-02-21 03:40:43.089739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2025-02-21 03:40:43.096209: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-21 03:40:43.301430: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2025-02-21 03:45:39,785] Trial 0 finished with value: 8.124001502990723 and parameters: {'batch_size': 128, 'units_1': 160, 'l1_1_layer1': 0.19290151906904532, 'l2_1_layer1': 0.21412663216085948, 'l1_2_layer1': 0.14336488255151417, 'l2_2_layer1': 0.1453422641729747, 'dropout_1': 0.0021499697659476315, 'units_2': 96, 'l2_1_layer2': 0.20438063919321223, 'l2_2_layer2': 0.23627214118419423, 'dropout_2': 0.16160325222159508, 'units_3': 192, 'l2_1_layer3': 0.04736564924274781, 'l2_2_layer3': 0.2328429475642924, 'dropout_3': 0.2549552110282706, 'unit_4': 256, 'dropout_4': 0.06999299838698327, 'unit_5': 192, 'Dense_1': 64, 'Dense_2': 96, 'learning_rate': 0.007834670908833734, 'clip_norm': 1.9922534122398303}. Best is trial 0 with value: 8.124001502990723.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cb1be-c808-450f-99e9-10dbe4ff8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best trial:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891f4a8-b5c4-4f5c-a949-5595f4e6ddcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
